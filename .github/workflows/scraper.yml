name: Run Scraper

on:
  schedule:
    - cron: '0 */6 * * *'  # Run every 6 hours
  workflow_dispatch:  # Allows manual trigger

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3  # Updated to v3

      - name: Set up Node.js
        uses: actions/setup-node@v3  # Updated to v3
        with:
          node-version: '20'

      - name: Install dependencies
        # run: npm install
        run: npm ci

      - name: Install Chromium
        run: sudo apt-get install chromium-browser

      - name: Set Chromium path
        run: echo "CHROMIUM_PATH=$(which chromium-browser)" >> $GITHUB_ENV

      - name: Run scraper
        run: |
          echo "SUPABASE_URL=${{ secrets.SUPABASE_URL }}" >> .env
          echo "SUPABASE_KEY=${{ secrets.SUPABASE_KEY }}" >> .env
          node index.js
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}